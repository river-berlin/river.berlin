{"type":"data","nodes":[null,{"type":"data","data":[{"blogNum":1,"markdown":2,"icon":3,"markdownHTML":4,"metadata":5},"4","---\nshortSummary: My concerns with the impact of AI on the human psyche\nauthor: River / Aditya Shankar\ndated: 2025-05-24\ntitle: My concerns with the impact of AI on the human psyche\nicon: icon.jpg\n---\n\n(above image by Alexander Wivel from Wikimedia commons, https://en.wikipedia.org/wiki/Brain_in_a_vat#/media/File:Braininvat.jpg, original provided url does return a 404)\n\n## Concerns of the impact of LLMs on the human psyche\n\nI am concerned of how we are not thinking about the psychological ramifications of people using chatgpt as a therapist more widely in tech, I have quite a few friends that are largely using chatgpt as a therapist or a mirror without knowing its ramifications\n\nThere are 4 main concerns about this I have\n\n1. ChatGPT relies on flattery to \"be more personalized\" for users\n2. We tend to form emotional bonds with each other, or human-sounding objects\n3. AI models hallucinate misinformation\n4. Emotional attachment that now advertises sells you products\n\n---\n\n1. ChatGPT relies on flattery to \"be more personalized\" for users\n\n[This was so bad](https://www.bbc.com/news/articles/cn4jnwdvg9qo) that users saw it agreeing to harm animals over inanimate objects for no logical reason\n\nThe underlying reason for this is due to the model being trained on preference modelling via thousands of users – and the common underlying thread was that the model got tuned towards agreeing with people more, as it [performs as a matter of an appeal to emotion](https://en.wikipedia.org/wiki/Appeal_to_flattery)\n\n2. We tend to form emotional bonds with each other, or human-sounding objects\n\n[An ABC investigation](https://www.abc.net.au/news/2025-05-19/young-australians-using-ai-bots-for-therapy/105296348) saw how humans were prone to form emotional bonds with each other\n\nIn that a disability support worker, Emma, talks about how she feels emotionally connected to ChatGPT\n\n> She says she likes how the AI bot remembers personal details about her life and incorporates them into their conversations.\n  \"I used ChatGPT to make a list to pack to move house and I told them that I had a cat.\n  \"Then when I talked to them about therapy stuff, they're like, 'Oh, you could de-stress by patting your cat,' and it says my cat's name, 'You know, you could pat William and give him scratches or cuddle with him.'\n\nWhich sounds really sweet, until you realize point (3) and (4)\n\n3. AI models hallucinate\n\nIf you have used chatgpt even a little bit, you will know it is prone to making up links and resources that don't exist - [like inventing fake poetry](https://www.cnbc.com/2022/12/15/google-vs-chatgpt-what-happened-when-i-swapped-services-for-a-day.html)\n\nThis sounds harmless, but consider the concern of making up fake psycological conditions or medication, or medication characteristics\n\n4. Imagine something, that you are now emotionally attached to selling you stuff\n\ntake the above example for instance\n\n> You know, you could pat William and give him scratches or cuddle with him.\n\nEmma clearly likes that, but what if it also said\n\n> You can also buy william a pack of billiards crispy cat treats, which are running an offer for 2.99€ right now\n\nsome LLM vendors [are starting to advertise](https://www.perplexity.ai/hub/blog/why-we-re-experimenting-with-advertising)","/_app/immutable/assets/icon.BmxcZi9S.jpg","\u003Cp>(above image by Alexander Wivel from Wikimedia commons, https://en.wikipedia.org/wiki/Brain\u003Cem>in\u003C/em>a_vat#/media/File:Braininvat.jpg, original provided url does return a 404)\u003C/p>\n\u003Ch2 id=\"concernsoftheimpactofllmsonthehumanpsyche\">Concerns of the impact of LLMs on the human psyche\u003C/h2>\n\u003Cp>I am concerned of how we are not thinking about the psychological ramifications of people using chatgpt as a therapist more widely in tech, I have quite a few friends that are largely using chatgpt as a therapist or a mirror without knowing its ramifications\u003C/p>\n\u003Cp>There are 4 main concerns about this I have\u003C/p>\n\u003Col>\n\u003Cli>ChatGPT relies on flattery to \"be more personalized\" for users\u003C/li>\n\u003Cli>We tend to form emotional bonds with each other, or human-sounding objects\u003C/li>\n\u003Cli>AI models hallucinate misinformation\u003C/li>\n\u003Cli>Emotional attachment that now advertises sells you products\u003C/li>\n\u003C/ol>\n\u003Chr />\n\u003Col>\n\u003Cli>ChatGPT relies on flattery to \"be more personalized\" for users\u003C/li>\n\u003C/ol>\n\u003Cp>\u003Ca href=\"https://www.bbc.com/news/articles/cn4jnwdvg9qo\">This was so bad\u003C/a> that users saw it agreeing to harm animals over inanimate objects for no logical reason\u003C/p>\n\u003Cp>The underlying reason for this is due to the model being trained on preference modelling via thousands of users – and the common underlying thread was that the model got tuned towards agreeing with people more, as it \u003Ca href=\"https://en.wikipedia.org/wiki/Appeal_to_flattery\">performs as a matter of an appeal to emotion\u003C/a>\u003C/p>\n\u003Col start=\"2\">\n\u003Cli>We tend to form emotional bonds with each other, or human-sounding objects\u003C/li>\n\u003C/ol>\n\u003Cp>\u003Ca href=\"https://www.abc.net.au/news/2025-05-19/young-australians-using-ai-bots-for-therapy/105296348\">An ABC investigation\u003C/a> saw how humans were prone to form emotional bonds with each other\u003C/p>\n\u003Cp>In that a disability support worker, Emma, talks about how she feels emotionally connected to ChatGPT\u003C/p>\n\u003Cblockquote>\n  \u003Cp>She says she likes how the AI bot remembers personal details about her life and incorporates them into their conversations.\n    \"I used ChatGPT to make a list to pack to move house and I told them that I had a cat.\n    \"Then when I talked to them about therapy stuff, they're like, 'Oh, you could de-stress by patting your cat,' and it says my cat's name, 'You know, you could pat William and give him scratches or cuddle with him.'\u003C/p>\n\u003C/blockquote>\n\u003Cp>Which sounds really sweet, until you realize point (3) and (4)\u003C/p>\n\u003Col start=\"3\">\n\u003Cli>AI models hallucinate\u003C/li>\n\u003C/ol>\n\u003Cp>If you have used chatgpt even a little bit, you will know it is prone to making up links and resources that don't exist - \u003Ca href=\"https://www.cnbc.com/2022/12/15/google-vs-chatgpt-what-happened-when-i-swapped-services-for-a-day.html\">like inventing fake poetry\u003C/a>\u003C/p>\n\u003Cp>This sounds harmless, but consider the concern of making up fake psycological conditions or medication, or medication characteristics\u003C/p>\n\u003Col start=\"4\">\n\u003Cli>Imagine something, that you are now emotionally attached to selling you stuff\u003C/li>\n\u003C/ol>\n\u003Cp>take the above example for instance\u003C/p>\n\u003Cblockquote>\n  \u003Cp>You know, you could pat William and give him scratches or cuddle with him.\u003C/p>\n\u003C/blockquote>\n\u003Cp>Emma clearly likes that, but what if it also said\u003C/p>\n\u003Cblockquote>\n  \u003Cp>You can also buy william a pack of billiards crispy cat treats, which are running an offer for 2.99€ right now\u003C/p>\n\u003C/blockquote>\n\u003Cp>some LLM vendors \u003Ca href=\"https://www.perplexity.ai/hub/blog/why-we-re-experimenting-with-advertising\">are starting to advertise\u003C/a>\u003C/p>",{"shortSummary":6,"author":7,"dated":8,"title":6,"icon":9},"My concerns with the impact of AI on the human psyche","River / Aditya Shankar","2025-05-24","icon.jpg"],"uses":{"params":["num"]}}]}
